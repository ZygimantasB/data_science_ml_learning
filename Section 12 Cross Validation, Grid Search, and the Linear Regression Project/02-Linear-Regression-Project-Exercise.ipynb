{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'><img src='../Pierian_Data_Logo.png'/></a>\n",
    "___\n",
    "<center><em>Copyright by Pierian Data Inc.</em></center>\n",
    "<center><em>For more information, visit us at <a href='http://www.pieriandata.com'>www.pieriandata.com</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression Project Exercise "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have learned about feature engineering, cross validation, and grid search, let's test all your new skills with a project exercise in Machine Learning. This exercise will have a more guided approach, later on the ML projects will begin to be more open-ended. We'll start off with using the final version of the Ames Housing dataset we worked on through the feature engineering section of the course. Your goal will be to create a Linear Regression Model, train it on the data with the optimal parameters using a grid search, and then evaluate the model's capabilities on a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "---\n",
    "## Complete the tasks in bold\n",
    "\n",
    "**TASK: Run the cells under the Imports and Data section to make sure you have imported the correct general libraries as well as the correct datasets. Later on you may need to run further imports from scikit-learn.**\n",
    "\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:36:47.664247Z",
     "start_time": "2024-08-04T17:36:47.660520Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:36:47.729710Z",
     "start_time": "2024-08-04T17:36:47.664247Z"
    }
   },
   "source": [
    "df_path = Path('..') / 'DATA' / 'AMES_Final_DF.csv'\n",
    "df = pd.read_csv(df_path)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:36:47.750632Z",
     "start_time": "2024-08-04T17:36:47.730716Z"
    }
   },
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Lot Frontage  Lot Area  Overall Qual  Overall Cond  Year Built  \\\n",
       "0         141.0     31770             6             5        1960   \n",
       "1          80.0     11622             5             6        1961   \n",
       "2          81.0     14267             6             6        1958   \n",
       "3          93.0     11160             7             5        1968   \n",
       "4          74.0     13830             5             5        1997   \n",
       "\n",
       "   Year Remod/Add  Mas Vnr Area  BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  ...  \\\n",
       "0            1960         112.0         639.0           0.0        441.0  ...   \n",
       "1            1961           0.0         468.0         144.0        270.0  ...   \n",
       "2            1958         108.0         923.0           0.0        406.0  ...   \n",
       "3            1968           0.0        1065.0           0.0       1045.0  ...   \n",
       "4            1998           0.0         791.0           0.0        137.0  ...   \n",
       "\n",
       "   Sale Type_ConLw  Sale Type_New  Sale Type_Oth  Sale Type_VWD  \\\n",
       "0                0              0              0              0   \n",
       "1                0              0              0              0   \n",
       "2                0              0              0              0   \n",
       "3                0              0              0              0   \n",
       "4                0              0              0              0   \n",
       "\n",
       "   Sale Type_WD   Sale Condition_AdjLand  Sale Condition_Alloca  \\\n",
       "0              1                       0                      0   \n",
       "1              1                       0                      0   \n",
       "2              1                       0                      0   \n",
       "3              1                       0                      0   \n",
       "4              1                       0                      0   \n",
       "\n",
       "   Sale Condition_Family  Sale Condition_Normal  Sale Condition_Partial  \n",
       "0                      0                      1                       0  \n",
       "1                      0                      1                       0  \n",
       "2                      0                      1                       0  \n",
       "3                      0                      1                       0  \n",
       "4                      0                      1                       0  \n",
       "\n",
       "[5 rows x 274 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Year Built</th>\n",
       "      <th>Year Remod/Add</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Sale Type_ConLw</th>\n",
       "      <th>Sale Type_New</th>\n",
       "      <th>Sale Type_Oth</th>\n",
       "      <th>Sale Type_VWD</th>\n",
       "      <th>Sale Type_WD</th>\n",
       "      <th>Sale Condition_AdjLand</th>\n",
       "      <th>Sale Condition_Alloca</th>\n",
       "      <th>Sale Condition_Family</th>\n",
       "      <th>Sale Condition_Normal</th>\n",
       "      <th>Sale Condition_Partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1960</td>\n",
       "      <td>1960</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1961</td>\n",
       "      <td>1961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1958</td>\n",
       "      <td>1958</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1968</td>\n",
       "      <td>1968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1997</td>\n",
       "      <td>1998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 274 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:36:47.760429Z",
     "start_time": "2024-08-04T17:36:47.750632Z"
    }
   },
   "source": [
    "df.info()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2925 entries, 0 to 2924\n",
      "Columns: 274 entries, Lot Frontage to Sale Condition_Partial\n",
      "dtypes: float64(11), int64(263)\n",
      "memory usage: 6.1 MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: The label we are trying to predict is the SalePrice column. Separate out the data into X features and y labels**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:38:16.684551Z",
     "start_time": "2024-08-04T17:38:16.678218Z"
    }
   },
   "source": [
    "X = df.drop('SalePrice',axis=1)\n",
    "y = df['SalePrice']"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Use scikit-learn to split up X and y into a training set and test set. Since we will later be using a Grid Search strategy, set your test proportion to 10%. To get the same data split as the solutions notebook, you can specify random_state = 101**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:38:17.867728Z",
     "start_time": "2024-08-04T17:38:17.863657Z"
    }
   },
   "source": "from sklearn.model_selection import train_test_split",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:38:18.483257Z",
     "start_time": "2024-08-04T17:38:18.473684Z"
    }
   },
   "source": "X_test, X_train, y_test, y_train = train_test_split(X, y, test_size=0.1, random_state=101)",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: The dataset features has a variety of scales and units. For optimal regression performance, scale the X features. Take carefuly note of what to use for .fit() vs what to use for .transform()**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:38:19.422349Z",
     "start_time": "2024-08-04T17:38:19.419355Z"
    }
   },
   "source": "from sklearn.preprocessing import StandardScaler",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:38:21.427282Z",
     "start_time": "2024-08-04T17:38:21.424053Z"
    }
   },
   "source": "scaler = StandardScaler()",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:39:57.276210Z",
     "start_time": "2024-08-04T17:39:57.255563Z"
    }
   },
   "source": [
    "# scaler.fit(X_train)\n",
    "# scaler.transform(X_train)\n",
    "\n",
    "scaled_X_train = scaler.fit_transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: We will use an Elastic Net model. Create an instance of default ElasticNet model with scikit-learn**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:39:58.823196Z",
     "start_time": "2024-08-04T17:39:58.819176Z"
    }
   },
   "source": "from sklearn.linear_model import ElasticNet",
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:43:09.919013Z",
     "start_time": "2024-08-04T17:43:09.914662Z"
    }
   },
   "source": "base_elastic_net_model = ElasticNet(max_iter=1000000) # Fix errors ",
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK:  The Elastic Net model has two main parameters, alpha and the L1 ratio. Create a dictionary parameter grid of values for the ElasticNet. Feel free to play around with these values, keep in mind, you may not match up exactly with the solution choices**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:43:10.482508Z",
     "start_time": "2024-08-04T17:43:10.479387Z"
    }
   },
   "source": [
    "param_grid = {\n",
    "    'alpha': [0.1, 1, 5, 10, 100],\n",
    "    'l1_ratio': [0.1, 0.7, 0.99, 1]\n",
    "}"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Using scikit-learn create a GridSearchCV object and run a grid search for the best parameters for your model based on your scaled training data. [In case you are curious about the warnings you may recieve for certain parameter combinations](https://stackoverflow.com/questions/20681864/lasso-on-sklearn-does-not-converge)**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:43:11.411348Z",
     "start_time": "2024-08-04T17:43:11.408193Z"
    }
   },
   "source": "from sklearn.model_selection import GridSearchCV",
   "outputs": [],
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-04T17:43:11.743322Z",
     "start_time": "2024-08-04T17:43:11.740197Z"
    }
   },
   "source": [
    "grid_model = GridSearchCV(base_elastic_net_model, \n",
    "                          param_grid=param_grid, \n",
    "                          scoring='neg_mean_squared_error', \n",
    "                          cv=5, \n",
    "                          verbose=1)"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-08-04T17:43:13.102370Z"
    }
   },
   "source": "grid_model.fit(X_train, y_train)",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\DataSpell\\data_science_ml_learning\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.990e+10, tolerance: 1.195e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "F:\\DataSpell\\data_science_ml_learning\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.407e+10, tolerance: 1.087e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "F:\\DataSpell\\data_science_ml_learning\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.574e+10, tolerance: 1.266e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "F:\\DataSpell\\data_science_ml_learning\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.524e+10, tolerance: 1.309e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "F:\\DataSpell\\data_science_ml_learning\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 5.102e+10, tolerance: 1.251e+08\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Display the best combination of parameters for your model**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Display the best combination of parameters for your model\n",
    "best_params = grid_model.best_params_\n",
    "print(\"Best parameters found: \", best_params)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Evaluate your model's performance on the unseen 10% scaled test set. In the solutions notebook we achieved an MAE of $\\$$14149 and a RMSE of $\\$$20532**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "y_pred = grid_model.predict(scaled_X_test)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "from sklearn.metrics import mean_absolute_error, mean_squared_error",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "mean_absolute_error(y_test, y_pred)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "source": "np.sqrt(mean_squared_error(y_test, y_pred))",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great work!\n",
    "\n",
    "----"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
